---
layout: post
title:  "Adapting While Learning: Grounding LLMs for Scientific Problems with Intelligent Tool Usage Adaptation"
date:   2024-11-01 00:00:00 +00:00
image: /images/awl.png
categories: research
author: "<b>Bohan Lyu*</b>, Yadi Cao*, Duncan Watson-Parris, Leon Bergen, Taylor Berg-Kirkpatrick, Rose Yu"
authors: "<b>Bohan Lyu*</b>, Yadi Cao*, Duncan Watson-Parris, Leon Bergen, Taylor Berg-Kirkpatrick, Rose Yu"
venue: "<b>ICML 2025</b>, AAAI FSS ORAL"
arxiv: https://arxiv.org/abs/2411.00412
code: https://github.com/Rose-STL-Lab/Adapting-While-Learning
website: https://icml.cc/virtual/2025/poster/44034
selected: true
slides: /pdfs/AWL-FSS.pdf
youtube: https://youtu.be/EPhse_oOdEc?si=5L8PytRUhWp94vXQ
highlight: true
bibtex: |
    @inproceedings{
        lyu2025adapting,
        title={Adapting While Learning: Grounding {LLM}s for Scientific Problems with Tool Usage Adaptation},
        author={Bohan Lyu and Yadi Cao and Duncan Watson-Parris and Leon Bergen and Taylor Berg-Kirkpatrick and Rose Yu},
        booktitle={Forty-second International Conference on Machine Learning},
        year={2025},
        url={https://openreview.net/forum?id=owulFly8oQ}
    }
---
This work proposes a fine-tuning method where LLMs internalize tool-generated solutions (World Knowledge Distillation) and learn to switch between direct answers and tool use for complex problems (Tool Usage Adaptation). It outperforms GPT-4 and Claude-3.5 across six scientific benchmarks.